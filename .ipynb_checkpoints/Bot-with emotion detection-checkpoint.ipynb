{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chat bot api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatbot import Chat,reflections,multiFunctionCall\n",
    "import wikipedia\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia API connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whoIs(query,sessionID=\"general\"):\n",
    "    print(query)\n",
    "    try:\n",
    "        return wikipedia.summary(query)\n",
    "    except:\n",
    "        for newquery in wikipedia.search(query):\n",
    "            try:\n",
    "                return wikipedia.summary(newquery)\n",
    "            except:\n",
    "                pass\n",
    "    return \"I don't know about \"+query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Detector Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "import imutils\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import playsound\n",
    "# parameters for loading data and images\n",
    "detection_model_path = 'Emotion/haarcascade_files/haarcascade_frontalface_default.xml'\n",
    "emotion_model_path = 'Emotion/models/_mini_XCEPTION.102-0.66.hdf5'\n",
    "\n",
    "# hyper-parameters for bounding boxes shape\n",
    "# loading models\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\n",
    " \"neutral\"]\n",
    "\n",
    "def emo(query,sessionID=\"general\"):\n",
    "    cv2.namedWindow('your_face')\n",
    "    camera = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        frame = camera.read()[1]\n",
    "        frame = imutils.resize(frame,width=300)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n",
    "        frameClone = frame.copy()\n",
    "        if len(faces) > 0:\n",
    "            faces = sorted(faces, reverse=True,\n",
    "            key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "            (fX, fY, fW, fH) = faces\n",
    "            roi = gray[fY:fY + fH, fX:fX + fW]\n",
    "            roi = cv2.resize(roi, (64, 64))\n",
    "            roi = roi.astype(\"float\") / 255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi, axis=0)\n",
    "            \n",
    "            preds = emotion_classifier.predict(roi)[0]\n",
    "            emotion_probability = np.max(preds)\n",
    "            label = EMOTIONS[preds.argmax()]\n",
    "\n",
    "            ee = []\n",
    "            percent = []\n",
    "            for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
    "                ee.append(emotion)\n",
    "                percent.append(prob)\n",
    "            mp = percent.index(max(percent))\n",
    "\n",
    "        cv2.imshow('your_face', frameClone)\n",
    "        break\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    try:\n",
    "        return ee[mp] \n",
    "    except:\n",
    "        return \"I cannot see your face.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Identification Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['obama', 'pratik']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import face_recognition\n",
    "import glob\n",
    "users = glob.glob(\"Users\\*.jpg\")\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "for user in users:\n",
    "    user_image = face_recognition.load_image_file(user)\n",
    "    known_face_encodings.append(face_recognition.face_encodings(user_image)[0])\n",
    "    known_face_names.append(user.split(\"\\\\\")[1].split(\".\")[0])\n",
    "print(known_face_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "\n",
    "def identifyu(query=0,sessionID=\"general\"):\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "    # Load a sample picture and learn how to recognize it.\n",
    "\n",
    "\n",
    "    # while True:\n",
    "        # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "    rgb_frame = frame[:, :, ::-1]\n",
    "\n",
    "    # Find all the faces and face enqcodings in the frame of video\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "    name = \"Unknown\"\n",
    "    # Loop through each face in this frame of video\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # See if the face is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # If a match was found in known_face_encodings, just use the first one.\n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "            name = known_face_names[first_match_index]\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "    #webcam_preview = plt.imshow(frame)\n",
    "\n",
    "#     # Hit 'q' on the keyboard to quit!\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "#     break\n",
    "\n",
    "    # Release handle to the webcam\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Mood and Load The User template file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whathappen(query,sessionID=\"general\"):\n",
    "    aa = input()\n",
    "    nam = identifyu()\n",
    "    with open(nam+\".txt\", \"a\") as myfile:\n",
    "        myfile.write(aa)\n",
    "    return \"Would you like to tell me more about it?\"\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "def sas(sentence):\n",
    "    if analyser.polarity_scores(sentence)['pos']>analyser.polarity_scores(sentence)['neg']:\n",
    "        return \"happy\"\n",
    "    else:\n",
    "        return \"sad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    nam = identifyu()\n",
    "    call = multiFunctionCall({\"whoIs\":whoIs,\"emo\":emo, \"identifyu\":identifyu, \"whathappen\":whathappen})\n",
    "    if nam == \"Unknown\":\n",
    "        firstQuestion=\"Hi, I am chatbot.\"\n",
    "        template = \"Example.template\"\n",
    "    else :\n",
    "        firstQuestion=\"Hi \"+nam+\" , nice to see you again.\"\n",
    "        template = nam+\".template\"\n",
    "    Chat(template, reflections,call=call).converse(firstQuestion)\n",
    "    from os import path\n",
    "    if path.exists(nam+\".txt\"):\n",
    "        with open(nam+\".txt\", \"r\") as myfile:\n",
    "            daa = myfile.read()\n",
    "            with open(\"pratik.template\", \"r\") as myfile:\n",
    "                try:\n",
    "                    mood = (myfile.readlines()[-2][2]) == \"m\"\n",
    "                except:\n",
    "                    mood = False\n",
    "            if mood:\n",
    "                with open(nam+\".template\", \"r+\") as f:\n",
    "                    d = f.readlines()\n",
    "                    f.seek(0)\n",
    "                    for i in d[:-2]:\n",
    "                        f.write(i)\n",
    "                    f.truncate()\n",
    "            with open(nam+\".template\", \"a\") as myf:\n",
    "                myf.write(\"\\n{ mood : \"+sas(daa)+\" }\")\n",
    "                myf.write(\"\\n{ reason : \"+daa+\" }\")\n",
    "        os.remove(nam+\".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi pratik , nice to see you again.\n",
      "> It is a rough day today\n",
      "Would you like to talk about it?\n",
      "> yes\n",
      "Go ahead, tell me what happend.\n",
      "> bad time in two and a half men show\n",
      "bad time in two and a half men show\n",
      "Would you like to tell me more about it?\n",
      "> no\n",
      "no.\n",
      "> quit\n",
      "Thank you for talking with me.\n"
     ]
    }
   ],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ mood : sad }\n",
      "\n",
      "{ reason : bad time in two and a half men show }\n"
     ]
    }
   ],
   "source": [
    "with open(\"pratik.template\", \"r\") as myfile:\n",
    "    try:\n",
    "        mood = (myfile.readlines()[-2][2]) == \"m\"\n",
    "    except:\n",
    "        mood = False\n",
    "if mood:\n",
    "    with open(\"pratik.template\", \"r\") as myfile:\n",
    "        for line in myfile.readlines()[-2:]:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing below this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Chat(\"Example.template\", reflections,call=call).converse(firstQuestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Voice Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')       #getting details of current voice\n",
    "engine.setProperty('voice', voices[1].id)\n",
    "engine.say(\"I will speak this text\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init() # object creation\n",
    "\n",
    "\"\"\" RATE\"\"\"\n",
    "rate = engine.getProperty('rate')   # getting details of current speaking rate\n",
    "print (rate)                        #printing current voice rate\n",
    "engine.setProperty('rate', 125)     # setting up new voice rate\n",
    "\n",
    "\n",
    "\"\"\"VOLUME\"\"\"\n",
    "volume = engine.getProperty('volume')   #getting to know current volume level (min=0 and max=1)\n",
    "print (volume)                          #printing current volume level\n",
    "engine.setProperty('volume',1.0)    # setting up volume level  between 0 and 1\n",
    "\n",
    "\"\"\"VOICE\"\"\"\n",
    "voices = engine.getProperty('voices')       #getting details of current voice\n",
    "#engine.setProperty('voice', voices[0].id)  #changing index, changes voices. o for male\n",
    "engine.setProperty('voice', voices[1].id)   #changing index, changes voices. 1 for female\n",
    "\n",
    "engine.say(\"Hello World!\")\n",
    "engine.say('My current speaking rate is ' + str(rate))\n",
    "engine.runAndWait()\n",
    "engine.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "a = glob.glob(\"Users\\*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_image = face_recognition.load_image_file(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_face_encoding = face_recognition.face_encodings(obama_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(obama_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "users = glob.glob(\"Users\\*.jpg\")\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "users_face_encoding = []\n",
    "users_names = []\n",
    "\n",
    "for user in users:\n",
    "    user_image = face_recognition.load_image_file(user)\n",
    "    users_face_encoding.append(face_recognition.face_encodings(user_image))\n",
    "    users_names.append(user.split(\"\\\\\")[1])\n",
    "    plt.imshow(user_image)\n",
    "#print(users_names)\n",
    "    \n",
    "# obama_image = face_recognition.load_image_file(\"obama.jpg\")\n",
    "# obama_face_encoding = face_recognition.face_encodings(obama_image)[0]\n",
    "\n",
    "# # Load a second sample picture and learn how to recognize it.\n",
    "# biden_image = face_recognition.load_image_file(\"biden.jpg\")\n",
    "# biden_face_encoding = face_recognition.face_encodings(biden_image)[0]\n",
    "\n",
    "# # Create arrays of known face encodings and their names\n",
    "# known_face_encodings = [\n",
    "#     obama_face_encoding,\n",
    "#     biden_face_encoding\n",
    "# ]\n",
    "# known_face_names = [\n",
    "#     \"Barack Obama\",\n",
    "#     \"Pratik Savla\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    is_capturing, frame = vc.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    # makes the blues image look real colored\n",
    "    webcam_preview = plt.imshow(frame)    \n",
    "else:\n",
    "    is_capturing = False\n",
    "\n",
    "while is_capturing:\n",
    "    try:    # Lookout for a keyboardInterrupt to stop the script\n",
    "        is_capturing, frame = vc.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    # makes the blues image look real colored\n",
    "        webcam_preview.set_data(frame)\n",
    "        plt.draw()\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "        plt.pause(0.1)    # the pause time is = 1 / framerate\n",
    "    except KeyboardInterrupt:\n",
    "        vc.release()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    break\n",
    "\n",
    "# Release handle to the webcam\n",
    "vc.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"a\") as myfile:\n",
    "    myfile.write(\" appended text aaa \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pratik.template\", \"r\") as myfile:\n",
    "    try:\n",
    "        mood = (myfile.readlines()[-2][2]) == \"m\"\n",
    "    except:\n",
    "        mood = False\n",
    "if mood:\n",
    "    with open(\"pratik.template\", \"r\") as myfile:\n",
    "        print(myfile.readlines()[-2:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "path.exists(\"pratik.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat():\n",
    "    nam = identifyu()\n",
    "    call = multiFunctionCall({\"whoIs\":whoIs,\"emo\":emo, \"identifyu\":identifyu, \"whathappen\":whathappen})\n",
    "    if nam == \"Unknown\":\n",
    "        firstQuestion=\"Hi, I am chatbot.\"\n",
    "        template = \"Example.template\"\n",
    "    else :\n",
    "        firstQuestion=\"Hi \"+nam+\" , nice to see you again.\"\n",
    "        template = nam+\".template\"\n",
    "    Chat(template, reflections,call=call).converse(firstQuestion)\n",
    "    from os import path\n",
    "    if path.exists(nam+\".txt\"):\n",
    "        with open(nam+\".txt\", \"r\") as myfile:\n",
    "            daa = myfile.read()\n",
    "            with open(nam+\".template\", \"a\") as myf:\n",
    "                myf.write(\"\\n\\n{ mood : \"+daa+\" }\")\n",
    "        os.remove(nam+\".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whathappen(query,sessionID=\"general\"):\n",
    "    aa = input()\n",
    "    with open(\"pratik\"+\".txt\", \"a\") as myfile:\n",
    "        myfile.write(aa)\n",
    "    return \"Would you like to tell me more about it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "print(\"Today's date:\", today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = today.strftime(\"%d/%m/%Y\")\n",
    "print(\"d1 =\", d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today.strftime(\"%B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer_scores(\"It is a good day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
